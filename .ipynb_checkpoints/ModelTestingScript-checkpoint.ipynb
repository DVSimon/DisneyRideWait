{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy import stats\n",
    "from sklearn.metrics import explained_variance_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date         datetime  SPOSTMIN  SACTMIN DAYOFWEEK\n",
      "0        6/4/2013    6/4/2013 9:00      30.0      NaN   Tuesday\n",
      "1        6/4/2013    6/4/2013 9:30      30.0      NaN   Tuesday\n",
      "2        6/4/2013   6/4/2013 10:00      60.0      NaN   Tuesday\n",
      "3        6/4/2013   6/4/2013 10:30      60.0      NaN   Tuesday\n",
      "4        6/4/2013   6/4/2013 11:00      60.0      NaN   Tuesday\n",
      "5        6/4/2013   6/4/2013 11:30      90.0      NaN   Tuesday\n",
      "6        6/4/2013   6/4/2013 12:00      90.0      NaN   Tuesday\n",
      "7        6/4/2013   6/4/2013 13:00     120.0      NaN   Tuesday\n",
      "8        6/4/2013   6/4/2013 13:30     120.0      NaN   Tuesday\n",
      "9        6/4/2013   6/4/2013 14:00      90.0      NaN   Tuesday\n",
      "10       6/4/2013   6/4/2013 15:00      90.0      NaN   Tuesday\n",
      "11       6/4/2013   6/4/2013 15:30      90.0      NaN   Tuesday\n",
      "12       6/4/2013   6/4/2013 16:00      90.0      NaN   Tuesday\n",
      "13       6/4/2013   6/4/2013 16:00      90.0      NaN   Tuesday\n",
      "14       6/4/2013   6/4/2013 16:30     120.0      NaN   Tuesday\n",
      "15       6/4/2013   6/4/2013 17:00      90.0      NaN   Tuesday\n",
      "16       6/4/2013   6/4/2013 17:30     100.0      NaN   Tuesday\n",
      "17       6/4/2013   6/4/2013 18:00      90.0      NaN   Tuesday\n",
      "18       6/4/2013   6/4/2013 18:30     120.0      NaN   Tuesday\n",
      "19       6/4/2013   6/4/2013 19:00      90.0      NaN   Tuesday\n",
      "20       6/4/2013   6/4/2013 19:30      90.0      NaN   Tuesday\n",
      "21       6/4/2013   6/4/2013 20:00     100.0      NaN   Tuesday\n",
      "22       6/4/2013   6/4/2013 20:00      90.0      NaN   Tuesday\n",
      "23       6/4/2013   6/4/2013 20:30      60.0      NaN   Tuesday\n",
      "24       6/4/2013   6/4/2013 21:00      60.0      NaN   Tuesday\n",
      "25      5/23/2014   5/23/2014 7:12     120.0      NaN    Friday\n",
      "26      5/23/2014   5/23/2014 7:21      35.0      NaN    Friday\n",
      "27      5/23/2014   5/23/2014 7:32      90.0      NaN    Friday\n",
      "28      5/23/2014   5/23/2014 7:35      90.0      NaN    Friday\n",
      "29      5/23/2014   5/23/2014 7:45      60.0      NaN    Friday\n",
      "...           ...              ...       ...      ...       ...\n",
      "243898  3/31/2019  3/31/2019 19:35      90.0      NaN    Sunday\n",
      "243899  3/31/2019  3/31/2019 19:42      90.0      NaN    Sunday\n",
      "243900  3/31/2019  3/31/2019 19:49      85.0      NaN    Sunday\n",
      "243901  3/31/2019  3/31/2019 19:56      85.0      NaN    Sunday\n",
      "243902  3/31/2019  3/31/2019 20:00      85.0      NaN    Sunday\n",
      "243903  3/31/2019  3/31/2019 20:07      90.0      NaN    Sunday\n",
      "243904  3/31/2019  3/31/2019 20:14      90.0      NaN    Sunday\n",
      "243905  3/31/2019  3/31/2019 20:21      90.0      NaN    Sunday\n",
      "243906  3/31/2019  3/31/2019 20:27      85.0      NaN    Sunday\n",
      "243907  3/31/2019  3/31/2019 20:35      85.0      NaN    Sunday\n",
      "243908  3/31/2019  3/31/2019 20:42      85.0      NaN    Sunday\n",
      "243909  3/31/2019  3/31/2019 20:49      80.0      NaN    Sunday\n",
      "243910  3/31/2019  3/31/2019 20:56      80.0      NaN    Sunday\n",
      "243911  3/31/2019  3/31/2019 21:00      80.0      NaN    Sunday\n",
      "243912  3/31/2019  3/31/2019 21:07      75.0      NaN    Sunday\n",
      "243913  3/31/2019  3/31/2019 21:14      30.0      NaN    Sunday\n",
      "243914  3/31/2019  3/31/2019 21:21      30.0      NaN    Sunday\n",
      "243915  3/31/2019  3/31/2019 21:27      40.0      NaN    Sunday\n",
      "243916  3/31/2019  3/31/2019 21:35      40.0      NaN    Sunday\n",
      "243917  3/31/2019  3/31/2019 21:42      40.0      NaN    Sunday\n",
      "243918  3/31/2019  3/31/2019 21:47      55.0      NaN    Sunday\n",
      "243919  3/31/2019  3/31/2019 21:49      55.0      NaN    Sunday\n",
      "243920  3/31/2019  3/31/2019 21:56      45.0      NaN    Sunday\n",
      "243921  3/31/2019  3/31/2019 22:00      35.0      NaN    Sunday\n",
      "243922  3/31/2019  3/31/2019 22:07    -999.0      NaN    Sunday\n",
      "243923  3/31/2019  3/31/2019 22:14    -999.0      NaN    Sunday\n",
      "243924  3/31/2019  3/31/2019 22:21    -999.0      NaN    Sunday\n",
      "243925  3/31/2019  3/31/2019 22:27    -999.0      NaN    Sunday\n",
      "243926  3/31/2019  3/31/2019 22:35    -999.0      NaN    Sunday\n",
      "243927  3/31/2019  3/31/2019 22:42    -999.0      NaN    Sunday\n",
      "\n",
      "[243928 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df_initial = pd.read_csv('7_dwarfs_train.csv')\n",
    "print(df_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date              6/4/2013\n",
      "datetime     6/4/2013 9:00\n",
      "SPOSTMIN                30\n",
      "SACTMIN                NaN\n",
      "DAYOFWEEK          Tuesday\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_initial.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(df_initial.loc[0]['SACTMIN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_initial.loc[0]['datetime']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df_initial.iterrows():\n",
    "    if math.isnan(row['SPOSTMIN']):\n",
    "        df_initial.loc[index,'SPOSTMIN'] = df_initial.loc[index, 'SACTMIN']\n",
    "#     print(row['SPOSTMIN'], row['SACTMIN'])\n",
    "df_initial = df_initial.drop(columns=\"SACTMIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial = df_initial[df_initial['SPOSTMIN'] != -999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date         datetime  SPOSTMIN DAYOFWEEK\n",
      "0        6/4/2013    6/4/2013 9:00      30.0   Tuesday\n",
      "1        6/4/2013    6/4/2013 9:30      30.0   Tuesday\n",
      "2        6/4/2013   6/4/2013 10:00      60.0   Tuesday\n",
      "3        6/4/2013   6/4/2013 10:30      60.0   Tuesday\n",
      "4        6/4/2013   6/4/2013 11:00      60.0   Tuesday\n",
      "5        6/4/2013   6/4/2013 11:30      90.0   Tuesday\n",
      "6        6/4/2013   6/4/2013 12:00      90.0   Tuesday\n",
      "7        6/4/2013   6/4/2013 13:00     120.0   Tuesday\n",
      "8        6/4/2013   6/4/2013 13:30     120.0   Tuesday\n",
      "9        6/4/2013   6/4/2013 14:00      90.0   Tuesday\n",
      "10       6/4/2013   6/4/2013 15:00      90.0   Tuesday\n",
      "11       6/4/2013   6/4/2013 15:30      90.0   Tuesday\n",
      "12       6/4/2013   6/4/2013 16:00      90.0   Tuesday\n",
      "13       6/4/2013   6/4/2013 16:00      90.0   Tuesday\n",
      "14       6/4/2013   6/4/2013 16:30     120.0   Tuesday\n",
      "15       6/4/2013   6/4/2013 17:00      90.0   Tuesday\n",
      "16       6/4/2013   6/4/2013 17:30     100.0   Tuesday\n",
      "17       6/4/2013   6/4/2013 18:00      90.0   Tuesday\n",
      "18       6/4/2013   6/4/2013 18:30     120.0   Tuesday\n",
      "19       6/4/2013   6/4/2013 19:00      90.0   Tuesday\n",
      "20       6/4/2013   6/4/2013 19:30      90.0   Tuesday\n",
      "21       6/4/2013   6/4/2013 20:00     100.0   Tuesday\n",
      "22       6/4/2013   6/4/2013 20:00      90.0   Tuesday\n",
      "23       6/4/2013   6/4/2013 20:30      60.0   Tuesday\n",
      "24       6/4/2013   6/4/2013 21:00      60.0   Tuesday\n",
      "25      5/23/2014   5/23/2014 7:12     120.0    Friday\n",
      "26      5/23/2014   5/23/2014 7:21      35.0    Friday\n",
      "27      5/23/2014   5/23/2014 7:32      90.0    Friday\n",
      "28      5/23/2014   5/23/2014 7:35      90.0    Friday\n",
      "29      5/23/2014   5/23/2014 7:45      60.0    Friday\n",
      "...           ...              ...       ...       ...\n",
      "243892  3/31/2019  3/31/2019 18:56      90.0    Sunday\n",
      "243893  3/31/2019  3/31/2019 19:00      90.0    Sunday\n",
      "243894  3/31/2019  3/31/2019 19:07      90.0    Sunday\n",
      "243895  3/31/2019  3/31/2019 19:14      90.0    Sunday\n",
      "243896  3/31/2019  3/31/2019 19:21      90.0    Sunday\n",
      "243897  3/31/2019  3/31/2019 19:27      90.0    Sunday\n",
      "243898  3/31/2019  3/31/2019 19:35      90.0    Sunday\n",
      "243899  3/31/2019  3/31/2019 19:42      90.0    Sunday\n",
      "243900  3/31/2019  3/31/2019 19:49      85.0    Sunday\n",
      "243901  3/31/2019  3/31/2019 19:56      85.0    Sunday\n",
      "243902  3/31/2019  3/31/2019 20:00      85.0    Sunday\n",
      "243903  3/31/2019  3/31/2019 20:07      90.0    Sunday\n",
      "243904  3/31/2019  3/31/2019 20:14      90.0    Sunday\n",
      "243905  3/31/2019  3/31/2019 20:21      90.0    Sunday\n",
      "243906  3/31/2019  3/31/2019 20:27      85.0    Sunday\n",
      "243907  3/31/2019  3/31/2019 20:35      85.0    Sunday\n",
      "243908  3/31/2019  3/31/2019 20:42      85.0    Sunday\n",
      "243909  3/31/2019  3/31/2019 20:49      80.0    Sunday\n",
      "243910  3/31/2019  3/31/2019 20:56      80.0    Sunday\n",
      "243911  3/31/2019  3/31/2019 21:00      80.0    Sunday\n",
      "243912  3/31/2019  3/31/2019 21:07      75.0    Sunday\n",
      "243913  3/31/2019  3/31/2019 21:14      30.0    Sunday\n",
      "243914  3/31/2019  3/31/2019 21:21      30.0    Sunday\n",
      "243915  3/31/2019  3/31/2019 21:27      40.0    Sunday\n",
      "243916  3/31/2019  3/31/2019 21:35      40.0    Sunday\n",
      "243917  3/31/2019  3/31/2019 21:42      40.0    Sunday\n",
      "243918  3/31/2019  3/31/2019 21:47      55.0    Sunday\n",
      "243919  3/31/2019  3/31/2019 21:49      55.0    Sunday\n",
      "243920  3/31/2019  3/31/2019 21:56      45.0    Sunday\n",
      "243921  3/31/2019  3/31/2019 22:00      35.0    Sunday\n",
      "\n",
      "[227645 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial['Month'] = df_initial.date.str.split('/').str[0]\n",
    "df_initial['Day'] = df_initial.date.str.split('/').str[1]\n",
    "df_initial['Year'] = df_initial.date.str.rsplit('/', 1).str[1]\n",
    "df_initial['Time_char'] = df_initial.datetime.str.split(' ').str[1]\n",
    "df_initial['Hour'] = df_initial['Time_char'].str.split(':').str[0]\n",
    "df_initial['Minute'] = df_initial['Time_char'].str.split(':').str[1]\n",
    "df_initial = df_initial.drop(columns=\"Time_char\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date         datetime  SPOSTMIN DAYOFWEEK Month Day  Year Hour  \\\n",
      "0        6/4/2013    6/4/2013 9:00      30.0   Tuesday     6   4  2013    9   \n",
      "1        6/4/2013    6/4/2013 9:30      30.0   Tuesday     6   4  2013    9   \n",
      "2        6/4/2013   6/4/2013 10:00      60.0   Tuesday     6   4  2013   10   \n",
      "3        6/4/2013   6/4/2013 10:30      60.0   Tuesday     6   4  2013   10   \n",
      "4        6/4/2013   6/4/2013 11:00      60.0   Tuesday     6   4  2013   11   \n",
      "5        6/4/2013   6/4/2013 11:30      90.0   Tuesday     6   4  2013   11   \n",
      "6        6/4/2013   6/4/2013 12:00      90.0   Tuesday     6   4  2013   12   \n",
      "7        6/4/2013   6/4/2013 13:00     120.0   Tuesday     6   4  2013   13   \n",
      "8        6/4/2013   6/4/2013 13:30     120.0   Tuesday     6   4  2013   13   \n",
      "9        6/4/2013   6/4/2013 14:00      90.0   Tuesday     6   4  2013   14   \n",
      "10       6/4/2013   6/4/2013 15:00      90.0   Tuesday     6   4  2013   15   \n",
      "11       6/4/2013   6/4/2013 15:30      90.0   Tuesday     6   4  2013   15   \n",
      "12       6/4/2013   6/4/2013 16:00      90.0   Tuesday     6   4  2013   16   \n",
      "13       6/4/2013   6/4/2013 16:00      90.0   Tuesday     6   4  2013   16   \n",
      "14       6/4/2013   6/4/2013 16:30     120.0   Tuesday     6   4  2013   16   \n",
      "15       6/4/2013   6/4/2013 17:00      90.0   Tuesday     6   4  2013   17   \n",
      "16       6/4/2013   6/4/2013 17:30     100.0   Tuesday     6   4  2013   17   \n",
      "17       6/4/2013   6/4/2013 18:00      90.0   Tuesday     6   4  2013   18   \n",
      "18       6/4/2013   6/4/2013 18:30     120.0   Tuesday     6   4  2013   18   \n",
      "19       6/4/2013   6/4/2013 19:00      90.0   Tuesday     6   4  2013   19   \n",
      "20       6/4/2013   6/4/2013 19:30      90.0   Tuesday     6   4  2013   19   \n",
      "21       6/4/2013   6/4/2013 20:00     100.0   Tuesday     6   4  2013   20   \n",
      "22       6/4/2013   6/4/2013 20:00      90.0   Tuesday     6   4  2013   20   \n",
      "23       6/4/2013   6/4/2013 20:30      60.0   Tuesday     6   4  2013   20   \n",
      "24       6/4/2013   6/4/2013 21:00      60.0   Tuesday     6   4  2013   21   \n",
      "25      5/23/2014   5/23/2014 7:12     120.0    Friday     5  23  2014    7   \n",
      "26      5/23/2014   5/23/2014 7:21      35.0    Friday     5  23  2014    7   \n",
      "27      5/23/2014   5/23/2014 7:32      90.0    Friday     5  23  2014    7   \n",
      "28      5/23/2014   5/23/2014 7:35      90.0    Friday     5  23  2014    7   \n",
      "29      5/23/2014   5/23/2014 7:45      60.0    Friday     5  23  2014    7   \n",
      "...           ...              ...       ...       ...   ...  ..   ...  ...   \n",
      "243892  3/31/2019  3/31/2019 18:56      90.0    Sunday     3  31  2019   18   \n",
      "243893  3/31/2019  3/31/2019 19:00      90.0    Sunday     3  31  2019   19   \n",
      "243894  3/31/2019  3/31/2019 19:07      90.0    Sunday     3  31  2019   19   \n",
      "243895  3/31/2019  3/31/2019 19:14      90.0    Sunday     3  31  2019   19   \n",
      "243896  3/31/2019  3/31/2019 19:21      90.0    Sunday     3  31  2019   19   \n",
      "243897  3/31/2019  3/31/2019 19:27      90.0    Sunday     3  31  2019   19   \n",
      "243898  3/31/2019  3/31/2019 19:35      90.0    Sunday     3  31  2019   19   \n",
      "243899  3/31/2019  3/31/2019 19:42      90.0    Sunday     3  31  2019   19   \n",
      "243900  3/31/2019  3/31/2019 19:49      85.0    Sunday     3  31  2019   19   \n",
      "243901  3/31/2019  3/31/2019 19:56      85.0    Sunday     3  31  2019   19   \n",
      "243902  3/31/2019  3/31/2019 20:00      85.0    Sunday     3  31  2019   20   \n",
      "243903  3/31/2019  3/31/2019 20:07      90.0    Sunday     3  31  2019   20   \n",
      "243904  3/31/2019  3/31/2019 20:14      90.0    Sunday     3  31  2019   20   \n",
      "243905  3/31/2019  3/31/2019 20:21      90.0    Sunday     3  31  2019   20   \n",
      "243906  3/31/2019  3/31/2019 20:27      85.0    Sunday     3  31  2019   20   \n",
      "243907  3/31/2019  3/31/2019 20:35      85.0    Sunday     3  31  2019   20   \n",
      "243908  3/31/2019  3/31/2019 20:42      85.0    Sunday     3  31  2019   20   \n",
      "243909  3/31/2019  3/31/2019 20:49      80.0    Sunday     3  31  2019   20   \n",
      "243910  3/31/2019  3/31/2019 20:56      80.0    Sunday     3  31  2019   20   \n",
      "243911  3/31/2019  3/31/2019 21:00      80.0    Sunday     3  31  2019   21   \n",
      "243912  3/31/2019  3/31/2019 21:07      75.0    Sunday     3  31  2019   21   \n",
      "243913  3/31/2019  3/31/2019 21:14      30.0    Sunday     3  31  2019   21   \n",
      "243914  3/31/2019  3/31/2019 21:21      30.0    Sunday     3  31  2019   21   \n",
      "243915  3/31/2019  3/31/2019 21:27      40.0    Sunday     3  31  2019   21   \n",
      "243916  3/31/2019  3/31/2019 21:35      40.0    Sunday     3  31  2019   21   \n",
      "243917  3/31/2019  3/31/2019 21:42      40.0    Sunday     3  31  2019   21   \n",
      "243918  3/31/2019  3/31/2019 21:47      55.0    Sunday     3  31  2019   21   \n",
      "243919  3/31/2019  3/31/2019 21:49      55.0    Sunday     3  31  2019   21   \n",
      "243920  3/31/2019  3/31/2019 21:56      45.0    Sunday     3  31  2019   21   \n",
      "243921  3/31/2019  3/31/2019 22:00      35.0    Sunday     3  31  2019   22   \n",
      "\n",
      "       Minute  \n",
      "0          00  \n",
      "1          30  \n",
      "2          00  \n",
      "3          30  \n",
      "4          00  \n",
      "5          30  \n",
      "6          00  \n",
      "7          00  \n",
      "8          30  \n",
      "9          00  \n",
      "10         00  \n",
      "11         30  \n",
      "12         00  \n",
      "13         00  \n",
      "14         30  \n",
      "15         00  \n",
      "16         30  \n",
      "17         00  \n",
      "18         30  \n",
      "19         00  \n",
      "20         30  \n",
      "21         00  \n",
      "22         00  \n",
      "23         30  \n",
      "24         00  \n",
      "25         12  \n",
      "26         21  \n",
      "27         32  \n",
      "28         35  \n",
      "29         45  \n",
      "...       ...  \n",
      "243892     56  \n",
      "243893     00  \n",
      "243894     07  \n",
      "243895     14  \n",
      "243896     21  \n",
      "243897     27  \n",
      "243898     35  \n",
      "243899     42  \n",
      "243900     49  \n",
      "243901     56  \n",
      "243902     00  \n",
      "243903     07  \n",
      "243904     14  \n",
      "243905     21  \n",
      "243906     27  \n",
      "243907     35  \n",
      "243908     42  \n",
      "243909     49  \n",
      "243910     56  \n",
      "243911     00  \n",
      "243912     07  \n",
      "243913     14  \n",
      "243914     21  \n",
      "243915     27  \n",
      "243916     35  \n",
      "243917     42  \n",
      "243918     47  \n",
      "243919     49  \n",
      "243920     56  \n",
      "243921     00  \n",
      "\n",
      "[227645 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial['Month'] = (df_initial['Month']).astype(int)\n",
    "df_initial['Day'] = (df_initial['Day']).astype(int)\n",
    "df_initial['Year'] = (df_initial['Year']).astype(int)\n",
    "df_initial['Hour'] = (df_initial['Hour']).astype(int)\n",
    "df_initial['Minute'] = (df_initial['Minute']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date         datetime  SPOSTMIN DAYOFWEEK  Month  Day  Year  \\\n",
      "0        6/4/2013    6/4/2013 9:00      30.0   Tuesday      6    4  2013   \n",
      "1        6/4/2013    6/4/2013 9:30      30.0   Tuesday      6    4  2013   \n",
      "2        6/4/2013   6/4/2013 10:00      60.0   Tuesday      6    4  2013   \n",
      "3        6/4/2013   6/4/2013 10:30      60.0   Tuesday      6    4  2013   \n",
      "4        6/4/2013   6/4/2013 11:00      60.0   Tuesday      6    4  2013   \n",
      "5        6/4/2013   6/4/2013 11:30      90.0   Tuesday      6    4  2013   \n",
      "6        6/4/2013   6/4/2013 12:00      90.0   Tuesday      6    4  2013   \n",
      "7        6/4/2013   6/4/2013 13:00     120.0   Tuesday      6    4  2013   \n",
      "8        6/4/2013   6/4/2013 13:30     120.0   Tuesday      6    4  2013   \n",
      "9        6/4/2013   6/4/2013 14:00      90.0   Tuesday      6    4  2013   \n",
      "10       6/4/2013   6/4/2013 15:00      90.0   Tuesday      6    4  2013   \n",
      "11       6/4/2013   6/4/2013 15:30      90.0   Tuesday      6    4  2013   \n",
      "12       6/4/2013   6/4/2013 16:00      90.0   Tuesday      6    4  2013   \n",
      "13       6/4/2013   6/4/2013 16:00      90.0   Tuesday      6    4  2013   \n",
      "14       6/4/2013   6/4/2013 16:30     120.0   Tuesday      6    4  2013   \n",
      "15       6/4/2013   6/4/2013 17:00      90.0   Tuesday      6    4  2013   \n",
      "16       6/4/2013   6/4/2013 17:30     100.0   Tuesday      6    4  2013   \n",
      "17       6/4/2013   6/4/2013 18:00      90.0   Tuesday      6    4  2013   \n",
      "18       6/4/2013   6/4/2013 18:30     120.0   Tuesday      6    4  2013   \n",
      "19       6/4/2013   6/4/2013 19:00      90.0   Tuesday      6    4  2013   \n",
      "20       6/4/2013   6/4/2013 19:30      90.0   Tuesday      6    4  2013   \n",
      "21       6/4/2013   6/4/2013 20:00     100.0   Tuesday      6    4  2013   \n",
      "22       6/4/2013   6/4/2013 20:00      90.0   Tuesday      6    4  2013   \n",
      "23       6/4/2013   6/4/2013 20:30      60.0   Tuesday      6    4  2013   \n",
      "24       6/4/2013   6/4/2013 21:00      60.0   Tuesday      6    4  2013   \n",
      "25      5/23/2014   5/23/2014 7:12     120.0    Friday      5   23  2014   \n",
      "26      5/23/2014   5/23/2014 7:21      35.0    Friday      5   23  2014   \n",
      "27      5/23/2014   5/23/2014 7:32      90.0    Friday      5   23  2014   \n",
      "28      5/23/2014   5/23/2014 7:35      90.0    Friday      5   23  2014   \n",
      "29      5/23/2014   5/23/2014 7:45      60.0    Friday      5   23  2014   \n",
      "...           ...              ...       ...       ...    ...  ...   ...   \n",
      "243892  3/31/2019  3/31/2019 18:56      90.0    Sunday      3   31  2019   \n",
      "243893  3/31/2019  3/31/2019 19:00      90.0    Sunday      3   31  2019   \n",
      "243894  3/31/2019  3/31/2019 19:07      90.0    Sunday      3   31  2019   \n",
      "243895  3/31/2019  3/31/2019 19:14      90.0    Sunday      3   31  2019   \n",
      "243896  3/31/2019  3/31/2019 19:21      90.0    Sunday      3   31  2019   \n",
      "243897  3/31/2019  3/31/2019 19:27      90.0    Sunday      3   31  2019   \n",
      "243898  3/31/2019  3/31/2019 19:35      90.0    Sunday      3   31  2019   \n",
      "243899  3/31/2019  3/31/2019 19:42      90.0    Sunday      3   31  2019   \n",
      "243900  3/31/2019  3/31/2019 19:49      85.0    Sunday      3   31  2019   \n",
      "243901  3/31/2019  3/31/2019 19:56      85.0    Sunday      3   31  2019   \n",
      "243902  3/31/2019  3/31/2019 20:00      85.0    Sunday      3   31  2019   \n",
      "243903  3/31/2019  3/31/2019 20:07      90.0    Sunday      3   31  2019   \n",
      "243904  3/31/2019  3/31/2019 20:14      90.0    Sunday      3   31  2019   \n",
      "243905  3/31/2019  3/31/2019 20:21      90.0    Sunday      3   31  2019   \n",
      "243906  3/31/2019  3/31/2019 20:27      85.0    Sunday      3   31  2019   \n",
      "243907  3/31/2019  3/31/2019 20:35      85.0    Sunday      3   31  2019   \n",
      "243908  3/31/2019  3/31/2019 20:42      85.0    Sunday      3   31  2019   \n",
      "243909  3/31/2019  3/31/2019 20:49      80.0    Sunday      3   31  2019   \n",
      "243910  3/31/2019  3/31/2019 20:56      80.0    Sunday      3   31  2019   \n",
      "243911  3/31/2019  3/31/2019 21:00      80.0    Sunday      3   31  2019   \n",
      "243912  3/31/2019  3/31/2019 21:07      75.0    Sunday      3   31  2019   \n",
      "243913  3/31/2019  3/31/2019 21:14      30.0    Sunday      3   31  2019   \n",
      "243914  3/31/2019  3/31/2019 21:21      30.0    Sunday      3   31  2019   \n",
      "243915  3/31/2019  3/31/2019 21:27      40.0    Sunday      3   31  2019   \n",
      "243916  3/31/2019  3/31/2019 21:35      40.0    Sunday      3   31  2019   \n",
      "243917  3/31/2019  3/31/2019 21:42      40.0    Sunday      3   31  2019   \n",
      "243918  3/31/2019  3/31/2019 21:47      55.0    Sunday      3   31  2019   \n",
      "243919  3/31/2019  3/31/2019 21:49      55.0    Sunday      3   31  2019   \n",
      "243920  3/31/2019  3/31/2019 21:56      45.0    Sunday      3   31  2019   \n",
      "243921  3/31/2019  3/31/2019 22:00      35.0    Sunday      3   31  2019   \n",
      "\n",
      "        Hour  Minute  \n",
      "0          9       0  \n",
      "1          9      30  \n",
      "2         10       0  \n",
      "3         10      30  \n",
      "4         11       0  \n",
      "5         11      30  \n",
      "6         12       0  \n",
      "7         13       0  \n",
      "8         13      30  \n",
      "9         14       0  \n",
      "10        15       0  \n",
      "11        15      30  \n",
      "12        16       0  \n",
      "13        16       0  \n",
      "14        16      30  \n",
      "15        17       0  \n",
      "16        17      30  \n",
      "17        18       0  \n",
      "18        18      30  \n",
      "19        19       0  \n",
      "20        19      30  \n",
      "21        20       0  \n",
      "22        20       0  \n",
      "23        20      30  \n",
      "24        21       0  \n",
      "25         7      12  \n",
      "26         7      21  \n",
      "27         7      32  \n",
      "28         7      35  \n",
      "29         7      45  \n",
      "...      ...     ...  \n",
      "243892    18      56  \n",
      "243893    19       0  \n",
      "243894    19       7  \n",
      "243895    19      14  \n",
      "243896    19      21  \n",
      "243897    19      27  \n",
      "243898    19      35  \n",
      "243899    19      42  \n",
      "243900    19      49  \n",
      "243901    19      56  \n",
      "243902    20       0  \n",
      "243903    20       7  \n",
      "243904    20      14  \n",
      "243905    20      21  \n",
      "243906    20      27  \n",
      "243907    20      35  \n",
      "243908    20      42  \n",
      "243909    20      49  \n",
      "243910    20      56  \n",
      "243911    21       0  \n",
      "243912    21       7  \n",
      "243913    21      14  \n",
      "243914    21      21  \n",
      "243915    21      27  \n",
      "243916    21      35  \n",
      "243917    21      42  \n",
      "243918    21      47  \n",
      "243919    21      49  \n",
      "243920    21      56  \n",
      "243921    22       0  \n",
      "\n",
      "[227645 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_initial.loc[0]['SPOSTMIN']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = df_initial['SPOSTMIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_DOW = LabelEncoder()\n",
    "DoW_feature = label_encoder_DOW.fit_transform(df_initial.DAYOFWEEK.iloc[:].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_col = pd.Series(DoW_feature)\n",
    "df_initial['DayOfWeek'] = DoW_feature\n",
    "df_initial = df_initial.drop(columns=[\"DAYOFWEEK\", \"date\", \"datetime\", \"SPOSTMIN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Month  Day  Year  Hour  Minute  DayOfWeek\n",
      "0           6    4  2013     9       0          5\n",
      "1           6    4  2013     9      30          5\n",
      "2           6    4  2013    10       0          5\n",
      "3           6    4  2013    10      30          5\n",
      "4           6    4  2013    11       0          5\n",
      "5           6    4  2013    11      30          5\n",
      "6           6    4  2013    12       0          5\n",
      "7           6    4  2013    13       0          5\n",
      "8           6    4  2013    13      30          5\n",
      "9           6    4  2013    14       0          5\n",
      "10          6    4  2013    15       0          5\n",
      "11          6    4  2013    15      30          5\n",
      "12          6    4  2013    16       0          5\n",
      "13          6    4  2013    16       0          5\n",
      "14          6    4  2013    16      30          5\n",
      "15          6    4  2013    17       0          5\n",
      "16          6    4  2013    17      30          5\n",
      "17          6    4  2013    18       0          5\n",
      "18          6    4  2013    18      30          5\n",
      "19          6    4  2013    19       0          5\n",
      "20          6    4  2013    19      30          5\n",
      "21          6    4  2013    20       0          5\n",
      "22          6    4  2013    20       0          5\n",
      "23          6    4  2013    20      30          5\n",
      "24          6    4  2013    21       0          5\n",
      "25          5   23  2014     7      12          0\n",
      "26          5   23  2014     7      21          0\n",
      "27          5   23  2014     7      32          0\n",
      "28          5   23  2014     7      35          0\n",
      "29          5   23  2014     7      45          0\n",
      "...       ...  ...   ...   ...     ...        ...\n",
      "243892      3   31  2019    18      56          3\n",
      "243893      3   31  2019    19       0          3\n",
      "243894      3   31  2019    19       7          3\n",
      "243895      3   31  2019    19      14          3\n",
      "243896      3   31  2019    19      21          3\n",
      "243897      3   31  2019    19      27          3\n",
      "243898      3   31  2019    19      35          3\n",
      "243899      3   31  2019    19      42          3\n",
      "243900      3   31  2019    19      49          3\n",
      "243901      3   31  2019    19      56          3\n",
      "243902      3   31  2019    20       0          3\n",
      "243903      3   31  2019    20       7          3\n",
      "243904      3   31  2019    20      14          3\n",
      "243905      3   31  2019    20      21          3\n",
      "243906      3   31  2019    20      27          3\n",
      "243907      3   31  2019    20      35          3\n",
      "243908      3   31  2019    20      42          3\n",
      "243909      3   31  2019    20      49          3\n",
      "243910      3   31  2019    20      56          3\n",
      "243911      3   31  2019    21       0          3\n",
      "243912      3   31  2019    21       7          3\n",
      "243913      3   31  2019    21      14          3\n",
      "243914      3   31  2019    21      21          3\n",
      "243915      3   31  2019    21      27          3\n",
      "243916      3   31  2019    21      35          3\n",
      "243917      3   31  2019    21      42          3\n",
      "243918      3   31  2019    21      47          3\n",
      "243919      3   31  2019    21      49          3\n",
      "243920      3   31  2019    21      56          3\n",
      "243921      3   31  2019    22       0          3\n",
      "\n",
      "[227645 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(max(df_initial.loc[:,'Month']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 5\n",
    "t_s = .20\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_initial, df_y, test_size = t_s, random_state = random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [100, 200, 300], #random int btwn 100 and 500 - removed\n",
    "              'learning_rate': stats.uniform(0.01, 0.08), #.01 + loc, range of .01+/-.08\n",
    "              'max_depth': [2, 4, 6, 8], #tree depths to check\n",
    "              'colsample_bytree': stats.uniform(0.3, 0.7) #btwn .1 and 1.0    \n",
    "}\n",
    "kfold = KFold(n_splits=3, shuffle=True, random_state=random_seed)\n",
    "model = XGBRegressor(tree_method='gpu_hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] colsample_bytree=0.3887050028875184, learning_rate=0.0345599515222534, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.3887050028875184, learning_rate=0.0345599515222534, max_depth=4, n_estimators=100, score=0.003166547434655498, total=   0.5s\n",
      "[CV] colsample_bytree=0.3887050028875184, learning_rate=0.0345599515222534, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.3887050028875184, learning_rate=0.0345599515222534, max_depth=4, n_estimators=100, score=-1.1407858197489928, total=   0.5s\n",
      "[CV] colsample_bytree=0.3887050028875184, learning_rate=0.0345599515222534, max_depth=4, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.3887050028875184, learning_rate=0.0345599515222534, max_depth=4, n_estimators=100, score=0.13813961176694733, total=   0.5s\n",
      "[CV] colsample_bytree=0.4115497058990862, learning_rate=0.07086579438147296, max_depth=8, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    1.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.4115497058990862, learning_rate=0.07086579438147296, max_depth=8, n_estimators=100, score=0.00442380023543365, total=   2.7s\n",
      "[CV] colsample_bytree=0.4115497058990862, learning_rate=0.07086579438147296, max_depth=8, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.4115497058990862, learning_rate=0.07086579438147296, max_depth=8, n_estimators=100, score=-3.8510379678138564, total=   2.5s\n",
      "[CV] colsample_bytree=0.4115497058990862, learning_rate=0.07086579438147296, max_depth=8, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    7.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.4115497058990862, learning_rate=0.07086579438147296, max_depth=8, n_estimators=100, score=-0.9759378693442846, total=   2.4s\n",
      "[CV] colsample_bytree=0.5850498702590529, learning_rate=0.08419332047662524, max_depth=8, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    9.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.5850498702590529, learning_rate=0.08419332047662524, max_depth=8, n_estimators=300, score=0.006411524588079365, total=  12.7s\n",
      "[CV] colsample_bytree=0.5850498702590529, learning_rate=0.08419332047662524, max_depth=8, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   22.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.5850498702590529, learning_rate=0.08419332047662524, max_depth=8, n_estimators=300, score=-86.73385278009383, total=  12.9s\n",
      "[CV] colsample_bytree=0.5850498702590529, learning_rate=0.08419332047662524, max_depth=8, n_estimators=300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   35.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  colsample_bytree=0.5850498702590529, learning_rate=0.08419332047662524, max_depth=8, n_estimators=300, score=-5.940947109091752, total=  12.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   48.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   48.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.333158 using {'colsample_bytree': 0.3887050028875184, 'learning_rate': 0.0345599515222534, 'max_depth': 4, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "rand_search = RandomizedSearchCV(model, param_distributions = param_grid, scoring = 'explained_variance', n_iter = 3, verbose = 10, cv=kfold)\n",
    "rand_result = rand_search.fit(X_train, y_train)\n",
    "print(\"Best: %f using %s\" % (rand_result.best_score_, rand_result.best_params_))\n",
    "best_XGB_estimator = rand_result.best_estimator_\n",
    "pickle.dump(best_XGB_estimator, open(\"xgb_dwarves.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.08, max_delta_step=0,\n",
       "       max_depth=7, min_child_weight=1, missing=None, n_estimators=300,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=0.75)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBRegressor(n_estimators=300, learning_rate=0.08, gamma=0, subsample=0.75, colsample_bytree=1, max_depth=7)\n",
    "xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.252192115333184\n"
     ]
    }
   ],
   "source": [
    "predictions = xgb.predict(X_test)\n",
    "print(explained_variance_score(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgb, open('xgb_dwarves_nonsearch.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = pickle.load(open('xgb_dwarves.pkl','rb'))\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day = df_initial.Day.values\n",
    "# month = df_initial.Month.values\n",
    "# year = df_initial.Year.values\n",
    "# hour = df_initial.Hour.values\n",
    "# minute = df_initial.Minute.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = []\n",
    "# columns.append(DoW_feature)\n",
    "# columns.append(month)\n",
    "# columns.append(day)\n",
    "# columns.append(year)\n",
    "# columns.append(hour)\n",
    "# columns.append(minute)\n",
    "# columns.append(DoW_feature)\n",
    "# encoded_features = column_stack(columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
